% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/mlumodest.R
\name{mlumodest}
\alias{mlumodest}
\title{MLU Model Estimation}
\usage{
mlumodest(
  D,
  X,
  Y,
  f,
  ML = c("Lasso", "Ridge", "RF", "CIF", "XGB", "CB", "Torch", "Logit_lasso", "OLS",
    "NLLS_exp", "loglin", "SL", "OLSensemble"),
  OLSensemble = NULL,
  SL.library = NULL,
  rf.cf.ntree = 500,
  rf.depth = NULL,
  mtry = NULL,
  cf.depth = Inf,
  polynomial.Lasso = 1,
  polynomial.Ridge = 1,
  polynomial.Logit_lasso = 1,
  polynomial.OLS = 1,
  polynomial.NLLS_exp = 1,
  polynomial.loglin = 1,
  xgb.nrounds = 200,
  xgb.max.depth = 6,
  cb.iterations = 500,
  cb.depth = 6,
  torch.epochs = 50,
  torch.hidden_units = c(64, 32),
  torch.lr = 0.01,
  torch.dropout = 0.2,
  ensemblefolds = 10,
  start_nlls = NULL,
  subsample = NULL,
  verbose = TRUE
)
}
\arguments{
\item{D}{Treatment assignment vector.}

\item{X}{Covariate dataframe or matrix.}

\item{Y}{Outcome vector.}

\item{f}{Function of Yi and Yj defining the dependent variable for the pair.}

\item{ML}{String vector specifying which machine learners to use.
Options: "Lasso", "Ridge", "RF", "CIF", "XGB", "CB", "Torch", "Logit_lasso", "OLS", "NLLS_exp", "loglin", "SL", "OLSensemble".}

\item{OLSensemble}{String vector specifying which learners should be used in OLS ensemble method.}

\item{SL.library}{String vector specifying which learners should be used in SuperLearner.}

\item{rf.cf.ntree}{How many trees should be grown when using RF or CIF. Default is 500.}

\item{rf.depth}{How deep should trees be grown in RF. NULL is default from ranger. Default is NULL.}

\item{mtry}{How many variables to consider at each split in RF. Default is max(floor(ncol(X)/3), 1).}

\item{cf.depth}{How deep should trees be grown in CIF. Inf is full depth. Default is Inf.}

\item{polynomial.Lasso}{Degree of polynomial to be fitted when using Lasso. 1 just fits the input X. 2 squares all variables and adds all pairwise interactions. Default is 1.}

\item{polynomial.Ridge}{Degree of polynomial to be fitted when using Ridge. See polynomial.Lasso for more info. Default is 1.}

\item{polynomial.Logit_lasso}{Degree of polynomial to be fitted when using Logit_lasso. See polynomial.Lasso for more info. Default is 1.}

\item{polynomial.OLS}{Degree of polynomial to be fitted when using OLS. See polynomial.Lasso for more info. Default is 1.}

\item{polynomial.NLLS_exp}{Degree of polynomial to be fitted when using NLLS_exp. See polynomial.Lasso for more info. Default is 1.}

\item{polynomial.loglin}{Degree of polynomial to be fitted when using loglin. See polynomial.Lasso for more info. Default is 1.}

\item{xgb.nrounds}{Integer specifying how many rounds to use in XGB. Default is 200.}

\item{xgb.max.depth}{Integer specifying how deep trees should be grown in XGB. Default is 6.}

\item{cb.iterations}{The maximum number of trees that can be built in CB. Default is 500.}

\item{cb.depth}{The depth of the trees in CB. Default is 6.}

\item{torch.epochs}{Integer specifying the number of epochs for Torch neural network. Default is 50.}

\item{torch.hidden_units}{Numeric vector specifying the number of neurons in each hidden layer of Torch neural network. Default is c(64, 32).}

\item{torch.lr}{Numeric value specifying the learning rate for Torch neural network. Default is 0.01.}

\item{torch.dropout}{Numeric value between 0 and 1 specifying the dropout rate for Torch neural network. Default is 0.2.}

\item{ensemblefolds}{Integer specifying how many folds to use in ensemble methods such as OLSensemble or SuperLearner. Default is 10.}

\item{start_nlls}{List with the starting values for NLLS_exp parameters. Default is log(mean(Y)) for intercept and zero for rest.}

\item{subsample}{Either NULL (use all data), a proportion between 0 and 1, or an integer number of observations to randomly subsample before creating pairs. This can significantly reduce computational time. Default is NULL.}

\item{verbose}{Logical specifying whether to print progress and model information. Default is TRUE.}
}
\value{
A model object from ML::modest().
}
\description{
Estimates a machine learning model for pairwise data structures.
Creates all possible pairs (i,j) where i < j and fits a model using
symmetric features: levels (sum of features) and distances (absolute differences).
}
\details{
The function creates pairwise features using symmetry:
  For each pair (i,j), the features are constructed as:
  [D[i] + D[j], X[i] + X[j], |D[i] - D[j]|, |X[i] - X[j]|]
  This representation respects the symmetric nature of pairwise data.
}
